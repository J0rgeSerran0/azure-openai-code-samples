{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use LLMs to generate synthetic data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import display, HTML, JSON, Markdown, Image\n",
    "import textwrap\n",
    "\n",
    "load_dotenv()\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "OPENAI_GPT4_DEPLOYMENT_NAME = os.getenv(\"OPENAI_GPT4_DEPLOYMENT_NAME\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = AZURE_OPENAI_ENDPOINT, \n",
    "  api_key=AZURE_OPENAI_API_KEY,  \n",
    "  api_version=\"2024-02-01\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openAI(text):\n",
    "    system_message = \"\"\"\n",
    "    Please read the following CONTEXT and generate two question and answer json objects in an array based on the CONTEXT provided. \n",
    "    The questions should require deep reading comprehension, logical inference, deduction, and connecting ideas across the text. \n",
    "    Avoid simplistic retrieval or pattern matching questions. Instead, focus on questions that test the ability to reason about the text in complex ways, draw subtle conclusions, and combine multiple pieces of information to arrive at an answer. Ensure that the questions are relevant, specific, and cover the key points of the CONTEXT.  Provide concise answers to each question, directly quoting the text from provided context. Provide the array output in strict JSON format as shown in output format. Ensure that the generated JSON is 100 percent structurally correct, with proper nesting, comma placement, and quotation marks. There should not be any comma after last element in the array.\n",
    "  \n",
    "    Output format:\n",
    "    [\n",
    "    {\n",
    "        \"question\": \"Question 1\",\n",
    "        \"answer\": \"Answer 1\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Question 2\",\n",
    "        \"answer\": \"Answer 2\"\n",
    "    }\n",
    "    ]\n",
    "\n",
    "    CONTEXT:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=OPENAI_GPT4_DEPLOYMENT_NAME,\n",
    "        messages = [\n",
    "            {\"role\":\"system\",\"content\":system_message},\n",
    "            {\"role\":\"user\",\"content\":text}\n",
    "            ],\n",
    "        temperature=1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def prettyprint(text: str) -> str:\n",
    "    print(textwrap.fill(text, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "```json\n",
       "[\n",
       "    {\n",
       "        \"question\": \"Why does CoH introduce a regularization term during pre-training, and how does it attempt to prevent overfitting?\",\n",
       "        \"answer\": \"CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset in order to avoid overfitting.\"\n",
       "    },\n",
       "    {\n",
       "        \"question\": \"What strategies does the agent employ to handle information that is not captured within its pre-trained model weights?\",\n",
       "        \"answer\": \"The agent learns to call external APIs for extra information, including current information, code execution capability, access to proprietary information sources, and more.\"\n",
       "    }\n",
       "]\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context = \"\"\"\n",
    "To avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens,\n",
    "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n",
    "\"\"\"\n",
    "answer = call_openAI(context)\n",
    "display(HTML(answer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
