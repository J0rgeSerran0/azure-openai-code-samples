{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "# To learn more, please visit the documentation - Quickstart: Azure Content Safety: https://aka.ms/acsstudiodoc\n",
    "#\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "#create a .env file with the following variables and replace with your values\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "OPENAI_GPT4_DEPLOYMENT_NAME = os.getenv(\"OPENAI_GPT4_DEPLOYMENT_NAME\")\n",
    "AZURE_SUBSCRIPTION_ID = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "AZURE_AISTUDIO_PROJECT_RESOURCE_GROUP = os.getenv(\"AZURE_AISTUDIO_PROJECT_RESOURCE_GROUP\")\n",
    "AZURE_AISTUDIO_PROJECT_NAME = os.getenv(\"AZURE_AISTUDIO_PROJECT_NAME\")\n",
    "api_version = \"2024-02-15-preview\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from promptflow.core import AzureOpenAIModelConfiguration\n",
    "\n",
    "# Initialize Azure OpenAI Connection with your environment variables\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_deployment=OPENAI_GPT4_DEPLOYMENT_NAME,\n",
    "    api_version=api_version,\n",
    ")\n",
    "override_model = {\"configuration\": model_config, \"parameters\": {\"max_tokens\": 512}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from promptflow.core import Prompty\n",
    "\n",
    "# load prompty as a flow\n",
    "flow = Prompty.load(source=\"./prompts/basic.prompty\", model=override_model)\n",
    "\n",
    "# execute the flow as function\n",
    "result = flow(question=\"What is the capital of France?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prompt flow service...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-09-09 16:39:57 +0300][promptflow][WARNING] - The starting prompt flow process did not finish within the timeout period. Kindly reminder: If you have previously upgraded the prompt flow package , please double-confirm that you have run '\u001b[1mpf service stop\u001b[0m' to stop the prompt flowservice before proceeding with the upgrade. Otherwise, you may encounter unexpected environmental issues or inconsistencies between the version of running prompt flow service and the local prompt flow version. Alternatively, you can use the '\u001b[1mpf upgrade\u001b[0m' command to proceed with the upgrade process for the prompt flow package.\n",
      "[2024-09-09 16:39:59 +0300][promptflow][WARNING] - Prompt flow service is not healthy. Kindly reminder: If you have previously upgraded the prompt flow package , please double-confirm that you have run '\u001b[1mpf service stop\u001b[0m' to stop the prompt flowservice before proceeding with the upgrade. Otherwise, you may encounter unexpected environmental issues or inconsistencies between the version of running prompt flow service and the local prompt flow version. Alternatively, you can use the '\u001b[1mpf upgrade\u001b[0m' command to proceed with the upgrade process for the prompt flow package.\n",
      "[2024-09-09 16:40:01 +0300][promptflow][WARNING] - Prompt flow service is not healthy, please check the logs for more details; traces might not be exported correctly.\n"
     ]
    }
   ],
   "source": [
    "from promptflow.tracing import start_trace\n",
    "\n",
    "# start a trace session, and print a url for user to check trace\n",
    "start_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Japan is Tokyo.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rerun the function, which will be recorded in the trace\n",
    "question = \"What is the capital of Japan?\"\n",
    "ground_truth = \"Tokyo\"\n",
    "result = flow(question=question)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': '5', 'explanation': 'Tokyo is the capital of Japan.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use prompty to test \n",
    "eval_flow = Prompty.load(\"./prompts/eval.prompty\", model=override_model)\n",
    "# execute the flow as function\n",
    "result = eval_flow(question=question, ground_truth=ground_truth, answer=result)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
