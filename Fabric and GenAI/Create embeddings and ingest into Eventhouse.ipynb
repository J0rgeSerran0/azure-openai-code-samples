{"cells":[{"cell_type":"markdown","source":["### Building a RAG with Fabric"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"2ad43d75-6a42-4b60-9338-1bbc4dd49732"},{"cell_type":"code","source":["%pip install openai==1.12.0 azure-kusto-data langchain tenacity langchain-openai pypdf"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":true,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"17d61d8e-d4ec-4815-ba89-f1fc28ff69b1"},{"cell_type":"code","source":["from openai import AzureOpenAI\n","from IPython.display import display, HTML\n","import os\n","import textwrap\n","import json \n","from notebookutils import mssparkutils\n","from azure.kusto.data import KustoClient, KustoConnectionStringBuilder\n","from azure.kusto.data.exceptions import KustoServiceError\n","from azure.kusto.data.helpers import dataframe_from_result_table\n","\n","from langchain.text_splitter import CharacterTextSplitter,RecursiveCharacterTextSplitter\n","from langchain_openai import AzureOpenAIEmbeddings\n","from langchain.document_loaders import PyPDFLoader\n","from tenacity import retry, wait_random_exponential, stop_after_attempt\n","\n","OPENAI_GPT4_DEPLOYMENT_NAME=\"gpt-4\"\n","OPENAI_DEPLOYMENT_ENDPOINT=\"https://aidemos-sweden.openai.azure.com/\" \n","OPENAI_API_KEY=\"c60a7d32643e4dab80136dbe6d1c834d\"\n","OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = \"text-embedding-ada-002\"\n","\n","KUSTO_URI = \"https://trd-2b081ftgtfnmaqabd1.z6.kusto.fabric.microsoft.com\"\n","KUSTO_DATABASE = \"GenAI_eventhouse\"\n","KUSTO_TABLE = \"bookEmbeddings\"\n","accessToken = mssparkutils.credentials.getToken(KUSTO_URI)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"00b8ee10-45c5-4f3d-9d8a-e929c863cd27"},{"cell_type":"code","source":["client = AzureOpenAI(\n","        azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,\n","        api_key=OPENAI_API_KEY,\n","        api_version=\"2023-09-01-preview\"\n","    )\n","\n","#we use the tenacity library to create delays and retries when calling openAI embeddings to avoid hitting throttling limits\n","@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n","def generate_embeddings(text): \n","    # replace newlines, which can negatively affect performance.\n","    txt = text.replace(\"\\n\", \" \")\n","    return client.embeddings.create(input = [txt], model=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME).data[0].embedding\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fa49e866-7f4e-41f6-a561-b11833309559"},{"cell_type":"markdown","source":["## Create embeddings for the data"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"c4715c42-baea-4521-8efa-38ab6ae17ca3"},{"cell_type":"code","source":["# splitting into 1000 char long chunks with 30 char overlap\n","# split [\"\\n\\n\", \"\\n\", \" \", \"\"]\n","splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=1000,\n","    chunk_overlap=30,\n",")\n","\n","documentName = \"moby dick book\"\n","#Copy File API path\n","fileName = \"/lakehouse/default/Files/moby dick.pdf\"\n","loader = PyPDFLoader(fileName)\n","pages = loader.load_and_split(text_splitter=splitter)\n","print(\"Number of pages: \", len(pages))"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e25a8a88"},{"cell_type":"code","source":["#save all the pages into a pandas dataframe\n","import pandas as pd\n","df = pd.DataFrame(columns=['document_name', 'content', 'embedding'])\n","for page in pages:\n","    df.loc[len(df.index)] = [documentName, page.page_content, \"\"]  \n","df.head()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"1c5637b4-3f6d-46ad-a78f-f99787f5dad4"},{"cell_type":"code","source":["# calculate the embeddings using openAI ada \n","\n","df[\"embedding\"] = df.content.apply(lambda x: generate_embeddings(x))\n","print(df.head(2))"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"e14446ae-ced1-4266-a6be-6e3f43ff38aa"},{"cell_type":"code","source":["#write the data to MS Fabric Eventhouse\n","df_sp = spark.createDataFrame(df)\n","\n","df_sp.write.\\\n","format(\"com.microsoft.kusto.spark.synapse.datasource\").\\\n","option(\"kustoCluster\",KUSTO_URI).\\\n","option(\"kustoDatabase\",KUSTO_DATABASE).\\\n","option(\"kustoTable\", KUSTO_TABLE).\\\n","option(\"accessToken\", accessToken ).\\\n","mode(\"Append\").save()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e8086768"},{"cell_type":"markdown","source":["### Vector search on Fabric Eventhouse"],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"f5be7384-5b76-4481-bc7c-1e6a504bf90b"},{"cell_type":"code","source":["def call_openAI(text):\n","    response = client.chat.completions.create(\n","        model=OPENAI_GPT4_DEPLOYMENT_NAME,\n","        messages = text,\n","        temperature=0\n","    )\n","\n","    return response.choices[0].message.content"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"b8c07e41-f19f-4141-9add-3e0a1ae2b4fc"},{"cell_type":"code","source":["def get_answer_from_eventhouse(question, nr_of_answers=1):\n","        searchedEmbedding = generate_embeddings(question)\n","        kusto_query = KUSTO_TABLE + \" | extend similarity = series_cosine_similarity(dynamic(\"+str(searchedEmbedding)+\"), embedding) | top \" + str(nr_of_answers) + \" by similarity desc \"\n","        kustoDf  = spark.read\\\n","        .format(\"com.microsoft.kusto.spark.synapse.datasource\")\\\n","        .option(\"kustoCluster\",KUSTO_URI)\\\n","        .option(\"kustoDatabase\",KUSTO_DATABASE)\\\n","        .option(\"accessToken\", accessToken)\\\n","        .option(\"kustoQuery\", kusto_query).load()\n","\n","        return kustoDf"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"77a1573c-b896-41ae-b9e9-cb04663ab1a4"},{"cell_type":"code","source":["nr_of_answers = 2\n","question = \"Why does the coffin prepared for Queequeg become Ishmael's life buoy once the Pequod sinks?\"\n","answers_df = get_answer_from_eventhouse(question, nr_of_answers)\n","\n","answer = \"\"\n","for row in answers_df.rdd.toLocalIterator():\n","    answer = answer + \" \" + row['content']\n","\n","prompt = 'Question: {}'.format(question) + '\\n' + 'Information: {}'.format(answer)\n","# prepare prompt\n","messages = [{\"role\": \"system\", \"content\": \"You are a HELPFUL assistant answering users questions. Answer the question using the provided information and do not add anything else.\"},\n","            {\"role\": \"user\", \"content\": prompt}]\n","\n","result = call_openAI(messages)\n","display(result)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"29e8e86d-7df7-45c1-93fd-93810d852aa5"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"orig_nbformat":4,"widgets":{},"synapse_widget":{"state":{},"version":"0.1"},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}