{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Environment variables from .env file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import display, HTML, JSON, Markdown, Image\n",
    "from neo4j import GraphDatabase\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter,RecursiveCharacterTextSplitter\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "import openai\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_GPT4_32k_DEPLOYMENT_NAME = os.getenv(\"OPENAI_GPT4_32k_DEPLOYMENT_NAME\")\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "api_version = \"2024-02-01\"\n",
    "\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    model=OPENAI_GPT4_32k_DEPLOYMENT_NAME,\n",
    "    azure_deployment=OPENAI_GPT4_32k_DEPLOYMENT_NAME,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "    openai_api_version=api_version,\n",
    ")\n",
    "\n",
    "client = openai.AzureOpenAI(\n",
    "        azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        api_version=\"2023-09-01-preview\"\n",
    "    )\n",
    "\n",
    "# define embeddings \n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,\n",
    "    azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "    openai_api_version=api_version,\n",
    "    chunk_size = 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def call_openAI(text):\n",
    "    response = llm.chat.completions.create(\n",
    "        model=OPENAI_GPT4_32k_DEPLOYMENT_NAME,\n",
    "        messages = text,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "#we use the tenacity library to create delays and retries when calling openAI embeddings to avoid hitting throttling limits\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def calc_embeddings(text):\n",
    "    deployment = OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\n",
    "    # replace newlines, which can negatively affect performance.\n",
    "    txt = text.replace(\"\\n\", \" \")\n",
    "    return embeddings.embed_query(txt)\n",
    "\n",
    "def prettyprint(text: str) -> str:\n",
    "    print(textwrap.fill(text, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "\n",
    "    system_message = \"\"\"\n",
    "        You are an assistant designed to extract entities from a text. \n",
    "        Users will paste in a string of text and you will respond with entities you have extracted from the text as a JSON object.\n",
    "        Here is an example of your output format:{aircraft_make:[],accident_number:[],aircraft_damage:[],location:[], phase_of_operation:[], pilot_flight_hours:[], injuries:[], engine_manufacturer:[], probable_cause:[], findings:[], ocurrence:[]}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=OPENAI_GPT4_32k_DEPLOYMENT_NAME,\n",
    "        messages = [\n",
    "            {\"role\":\"system\",\"content\":system_message},\n",
    "            {\"role\":\"user\",\"content\":text}\n",
    "            ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=20000,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20071229X02007.pdf']\n",
      "Number of pages:  4\n",
      "Entities:  {\"location\":[\"Tallahassee, FL\"],\"accident_number\":[\"NYC08CA055\"],\"date_time\":[\"12/08/2007, 1730 EST\"],\"aircraft\":[\"Piper PA-22-150\"],\"aircraft_damage\":[\"Substantial\"],\"injuries\":[\"1 Minor\"],\"pilot_age\":[\"85\"],\"pilot_flight_hours\":[\"2319 hours\"],\"engine_manufacturer\":[\"Lycoming\"],\"probable_cause\":[\"The pilot's misjudged clearance over obstacles during final approach.\"],\"findings\":[\"IN FLIGHT COLLISION WITH OBJECT\"],\"occurrence\":[\"APPROACH\"]}\n"
     ]
    }
   ],
   "source": [
    "# splitting into 1000 char long chunks with 30 char overlap\n",
    "# split [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=5000,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "pdf_folder_path = \"./data/test/\"\n",
    "print(os.listdir(pdf_folder_path))\n",
    "\n",
    "# read the pdf files and split them into chunks, extract entities and calculate embeddings\n",
    "embeddings_df = pd.DataFrame(columns=['document_name', 'content', 'embedding'])\n",
    "entities_df = pd.DataFrame(columns=['document_name', 'entities'])\n",
    "\n",
    "for file in os.listdir(pdf_folder_path):\n",
    "    if file.endswith('.pdf'):\n",
    "        pdf_path = os.path.join(pdf_folder_path, file)\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        # calculate embeddings\n",
    "        pages = loader.load_and_split(text_splitter=splitter)\n",
    "        print(\"Number of pages: \", len(pages))\n",
    "        all_pages = ''\n",
    "        for page in pages:\n",
    "            #save all the pages into a pandas dataframe\n",
    "            embeddings_df.loc[len(embeddings_df.index)] = [file, page.page_content, \"\"]  \n",
    "            all_pages += page.page_content\n",
    "\n",
    "        # extract entities from the whole document - we assume the document is less than 32k tokens (we are using GPT4 32k model)\n",
    "        entities = (extract_entities(all_pages))\n",
    "        print(\"Entities: \", entities)\n",
    "        entities_df.loc[len(entities_df.index)] = [file, entities]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        document_name                                            content  \\\n",
      "0  20071229X02007.pdf  Page 1 of 4\\nNational Transportation Safety Bo...   \n",
      "1  20071229X02007.pdf  Page 2 of 4 NYC08CA055Factual Information\\nPil...   \n",
      "\n",
      "                                           embedding  \n",
      "0  [-0.007549772970378399, -0.01652275212109089, ...  \n",
      "1  [0.006805323529988527, -0.002616920042783022, ...  \n"
     ]
    }
   ],
   "source": [
    "# calculate the embeddings using openAI ada \n",
    "embeddings_df[\"embedding\"] = embeddings_df.content.apply(lambda x: calc_embeddings(x))\n",
    "embeddings_df.to_csv('./data/embeddings/adx_embeddings.csv', index=False)\n",
    "print(embeddings_df.head(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
