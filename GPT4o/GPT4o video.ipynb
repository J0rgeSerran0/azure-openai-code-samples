{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Environment variables from .env file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import display, HTML, JSON, Markdown, Image\n",
    "\n",
    "load_dotenv()\n",
    "GPT4o_API_KEY = os.getenv(\"GPT4o_API_KEY\")\n",
    "GPT4o_DEPLOYMENT_ENDPOINT = os.getenv(\"GPT4o_DEPLOYMENT_ENDPOINT\")\n",
    "GPT4o_DEPLOYMENT_NAME = os.getenv(\"GPT4o_DEPLOYMENT_NAME\")\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = GPT4o_DEPLOYMENT_ENDPOINT, \n",
    "  api_key=GPT4o_API_KEY,  \n",
    "  api_version=\"2024-02-01\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openAI(text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=GPT4o_DEPLOYMENT_NAME,\n",
    "        messages = text,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imageio_ffmpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meditor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VideoFileClip\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbase64\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\moviepy\\editor.py:22\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThis file is meant to make it easy to load the main features of\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mMoviePy by simply typing:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03mclip.preview().\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Note that these imports could have been performed in the __init__.py\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# file, but this would make the loading of moviepy slower.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Clips\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mVideoFileClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VideoFileClip\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImageSequenceClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageSequenceClip\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download_webfile\n",
      "File \u001b[1;32mc:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\moviepy\\video\\io\\VideoFileClip.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mVideoClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VideoClip\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAudioFileClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioFileClip\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Clip\n",
      "File \u001b[1;32mc:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\moviepy\\video\\VideoClip.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m imread, imsave\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01maio\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mffmpeg_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ffmpeg_write_image, ffmpeg_write_video\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mffmpeg_tools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ffmpeg_merge_video_audio\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgif_writers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (write_gif,\n\u001b[0;32m     24\u001b[0m                              write_gif_with_tempfiles,\n\u001b[0;32m     25\u001b[0m                              write_gif_with_image_io)\n",
      "File \u001b[1;32mc:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_writer.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PY3, DEVNULL\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_setting\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m verbose_print\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFFMPEG_VideoWriter\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\moviepy\\config.py:34\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m FFMPEG_BINARY\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffmpeg-imageio\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mffmpeg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_exe\n\u001b[0;32m     35\u001b[0m     FFMPEG_BINARY \u001b[38;5;241m=\u001b[39m get_exe()\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m FFMPEG_BINARY\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto-detect\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\imageio\\plugins\\ffmpeg.py:143\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimageio_ffmpeg\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Format, image_as_uint\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imageio_ffmpeg'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# We'll be using the OpenAI DevDay Keynote Recap video. You can review the video here: https://www.youtube.com/watch?v=h02ti0Bl6zk\n",
    "VIDEO_PATH = \"data/keynote_recap.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, seconds_per_frame=2):\n",
    "    base64Frames = []\n",
    "    base_video_path, _ = os.path.splitext(video_path)\n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    frames_to_skip = int(fps * seconds_per_frame)\n",
    "    curr_frame=0\n",
    "\n",
    "    # Loop through the video and extract frames at specified sampling rate\n",
    "    while curr_frame < total_frames - 1:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, curr_frame)\n",
    "        success, frame = video.read()\n",
    "        if not success:\n",
    "            break\n",
    "        _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "        base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "        curr_frame += frames_to_skip\n",
    "    video.release()\n",
    "\n",
    "    # Extract audio from video\n",
    "    audio_path = f\"{base_video_path}.mp3\"\n",
    "    clip = VideoFileClip(video_path)\n",
    "    clip.audio.write_audiofile(audio_path, bitrate=\"32k\")\n",
    "    clip.audio.close()\n",
    "    clip.close()\n",
    "\n",
    "    print(f\"Extracted {len(base64Frames)} frames\")\n",
    "    print(f\"Extracted audio to {audio_path}\")\n",
    "    return base64Frames, audio_path\n",
    "\n",
    "# Extract 1 frame per second. You can adjust the `seconds_per_frame` parameter to change the sampling rate\n",
    "base64Frames, audio_path = process_video(VIDEO_PATH, seconds_per_frame=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Display the frames and audio for context\n",
    "display_handle = display(None, display_id=True)\n",
    "for img in base64Frames:\n",
    "    display_handle.update(Image(data=base64.b64decode(img.encode(\"utf-8\")), width=600))\n",
    "    time.sleep(0.025)\n",
    "\n",
    "Audio(audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Summarization\n",
    "Now that we have both the video frames and the audio, let's run a few different tests to generate a video summary to compare the results of using the models with different modalities. We should expect to see that the summary generated with context from both visual and audio inputs will be the most accurate, as the model is able to use the entire context from the video.\n",
    "\n",
    "- Visual Summary\n",
    "- Audio Summary\n",
    "- Visual + Audio Summary\n",
    "- Visual Summary  \n",
    "\n",
    "The visual summary is generated by sending the model only the frames from the video. With just the frames, the model is likely to capture the visual aspects, but will miss any details discussed by the speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages=[\n",
    "{\"role\": \"system\", \"content\": \"You are generating a video summary. Please provide a summary of the video. Respond in Markdown.\"},\n",
    "{\"role\": \"user\", \"content\": [\n",
    "    \"These are the frames from the video.\",\n",
    "    *map(lambda x: {\"type\": \"image_url\", \n",
    "                    \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, base64Frames)\n",
    "    ],\n",
    "}\n",
    "]\n",
    "result = call_openAI(messages)\n",
    "display(HTML(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
