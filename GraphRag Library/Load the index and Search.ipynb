{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Environment variables from .env file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "from graphrag.query.indexer_adapters import read_indexer_entities, read_indexer_reports\n",
    "from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.structured_search.global_search.community_context import (\n",
    "    GlobalCommunityContext,\n",
    ")\n",
    "from graphrag.query.structured_search.global_search.search import GlobalSearch\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_GPT35_DEPLOYMENT_NAME = os.getenv(\"OPENAI_GPT35_DEPLOYMENT_NAME\")\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME  = os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "\n",
    "\n",
    "GRAPHRAG_API_KEY = os.getenv(\"GRAPHRAG_API_KEY\")\n",
    "GRAPHRAG_LLM_MODEL = os.getenv(\"GRAPHRAG_LLM_MODEL\")\n",
    "GRAPHRAG_API_BASE= os.getenv(\"GRAPHRAG_API_BASE\")\n",
    "GRAPHRAG_API_VERSION = os.getenv(\"GRAPHRAG_API_VERSION\")\n",
    "GRAPHRAG_EMBEDDING_TYPE = os.getenv(\"GRAPHRAG_EMBEDDING_TYPE\")\n",
    "GRAPHRAG_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"GRAPHRAG_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "\n",
    "def init_llm(model=OPENAI_GPT35_DEPLOYMENT_NAME,\n",
    "             deployment_name=OPENAI_GPT35_DEPLOYMENT_NAME,\n",
    "             openai_api_version=\"2024-02-15-preview\",\n",
    "             temperature=0,\n",
    "             max_tokens=400\n",
    "             ):\n",
    "\n",
    "    llm = AzureChatOpenAI(deployment_name=deployment_name,\n",
    "                            model=model,\n",
    "                            openai_api_version=openai_api_version,\n",
    "                            azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "                            temperature=temperature,\n",
    "                            max_tokens=max_tokens\n",
    "                            )\n",
    "    return llm\n",
    "\n",
    "llm = init_llm()\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,\n",
    "    azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "    openai_api_version=\"2024-02-15-preview\",\n",
    "    chunk_size = 1\n",
    ")\n",
    "\n",
    "graphRagllm = ChatOpenAI(\n",
    "    api_key=GRAPHRAG_API_KEY,\n",
    "    model=GRAPHRAG_LLM_MODEL,\n",
    "    api_base = GRAPHRAG_API_BASE,\n",
    "    api_version = GRAPHRAG_API_VERSION,\n",
    "    api_type=OpenaiApiType.AzureOpenAI,  # OpenaiApiType.OpenAI or OpenaiApiType.AzureOpenAI\n",
    "    max_retries=20,\n",
    ")\n",
    "\n",
    "token_encoder = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the RAG index from the Faiss vector store to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the vector store to memory\n",
    "vectorStore = FAISS.load_local(\"./faiss/faiss_index\", embeddings, allow_dangerous_deserialization= True)\n",
    "retriever = vectorStore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})  # returns 2 most similar vectors/documents\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "It is difficult to determine the exact number of people mentioned in the book \"Moby-Dick\" by Herman Melville, as there are numerous characters, both major and minor, throughout the story. Additionally, there are many unnamed sailors and crew members mentioned in passing. However, the main characters include Ishmael, Captain Ahab, Queequeg, Starbuck, and various other crew members of the ship Pequod."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = qa.invoke({\"query\": \"How many people are mentioned in the book?\"})\n",
    "display(HTML(r['result']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the GraphRAG index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet files generated from indexing pipeline\n",
    "INPUT_DIR = \"./output/20240728-172720/artifacts/\"\n",
    "COMMUNITY_REPORT_TABLE = \"create_final_community_reports\"\n",
    "ENTITY_TABLE = \"create_final_nodes\"\n",
    "ENTITY_EMBEDDING_TABLE = \"create_final_entities\"\n",
    "\n",
    "\n",
    "# community level in the Leiden community hierarchy from which we will load the community reports\n",
    "# higher value means we use reports from more fine-grained communities (at the cost of higher computation cost)\n",
    "COMMUNITY_LEVEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report records: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\graphrag\\query\\indexer_adapters.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].fillna(-1)\n",
      "c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\graphrag\\query\\indexer_adapters.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>community</th>\n",
       "      <th>full_content</th>\n",
       "      <th>level</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>rank_explanation</th>\n",
       "      <th>summary</th>\n",
       "      <th>findings</th>\n",
       "      <th>full_content_json</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139</td>\n",
       "      <td># Stubb and the Pequod's Maritime Adventures\\n...</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Stubb and the Pequod's Maritime Adventures</td>\n",
       "      <td>The impact severity rating is moderate to high...</td>\n",
       "      <td>The community centers around Stubb, a key char...</td>\n",
       "      <td>[{'explanation': 'Stubb, as the second mate on...</td>\n",
       "      <td>{\\n    \"title\": \"Stubb and the Pequod's Mariti...</td>\n",
       "      <td>991b0fc2-063c-43a1-965f-d1beacc3d969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140</td>\n",
       "      <td># The Pequod's Whale Chase\\n\\nThis report exam...</td>\n",
       "      <td>3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>The Pequod's Whale Chase</td>\n",
       "      <td>The impact severity rating is relatively high ...</td>\n",
       "      <td>This report examines the community centered ar...</td>\n",
       "      <td>[{'explanation': 'Flask is a central figure in...</td>\n",
       "      <td>{\\n    \"title\": \"The Pequod's Whale Chase\",\\n ...</td>\n",
       "      <td>dda93d78-a8c6-4147-8533-d25f2cbe13a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141</td>\n",
       "      <td># Tashtego and The Conflict Aboard The Pequod\\...</td>\n",
       "      <td>3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Tashtego and The Conflict Aboard The Pequod</td>\n",
       "      <td>The impact severity rating is relatively high ...</td>\n",
       "      <td>The community is centered around the character...</td>\n",
       "      <td>[{'explanation': 'Tashtego is depicted as a da...</td>\n",
       "      <td>{\\n    \"title\": \"Tashtego and The Conflict Abo...</td>\n",
       "      <td>ed60ddc1-b01d-47b8-8693-28dfbb21f091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142</td>\n",
       "      <td># The Boat and the Whale Hunt\\n\\nThe community...</td>\n",
       "      <td>3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>The Boat and the Whale Hunt</td>\n",
       "      <td>The impact severity rating is high due to the ...</td>\n",
       "      <td>The community's narrative centers around 'The ...</td>\n",
       "      <td>[{'explanation': ''The Boat' is not only a phy...</td>\n",
       "      <td>{\\n    \"title\": \"The Boat and the Whale Hunt\",...</td>\n",
       "      <td>67d866e8-5804-482f-a279-a5e1565e91ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td># Brazil Banks and Right Whales Interaction\\n\\...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Brazil Banks and Right Whales Interaction</td>\n",
       "      <td>The impact severity rating is low to moderate,...</td>\n",
       "      <td>The community is centered around the interacti...</td>\n",
       "      <td>[{'explanation': 'Brazil Banks is described as...</td>\n",
       "      <td>{\\n    \"title\": \"Brazil Banks and Right Whales...</td>\n",
       "      <td>847adfb1-3f4a-4093-af5d-ea20c9039d8d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  community                                       full_content  level  rank  \\\n",
       "0       139  # Stubb and the Pequod's Maritime Adventures\\n...      3   4.5   \n",
       "1       140  # The Pequod's Whale Chase\\n\\nThis report exam...      3   7.5   \n",
       "2       141  # Tashtego and The Conflict Aboard The Pequod\\...      3   7.5   \n",
       "3       142  # The Boat and the Whale Hunt\\n\\nThe community...      3   7.5   \n",
       "4       100  # Brazil Banks and Right Whales Interaction\\n\\...      2   3.0   \n",
       "\n",
       "                                         title  \\\n",
       "0   Stubb and the Pequod's Maritime Adventures   \n",
       "1                     The Pequod's Whale Chase   \n",
       "2  Tashtego and The Conflict Aboard The Pequod   \n",
       "3                  The Boat and the Whale Hunt   \n",
       "4    Brazil Banks and Right Whales Interaction   \n",
       "\n",
       "                                    rank_explanation  \\\n",
       "0  The impact severity rating is moderate to high...   \n",
       "1  The impact severity rating is relatively high ...   \n",
       "2  The impact severity rating is relatively high ...   \n",
       "3  The impact severity rating is high due to the ...   \n",
       "4  The impact severity rating is low to moderate,...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The community centers around Stubb, a key char...   \n",
       "1  This report examines the community centered ar...   \n",
       "2  The community is centered around the character...   \n",
       "3  The community's narrative centers around 'The ...   \n",
       "4  The community is centered around the interacti...   \n",
       "\n",
       "                                            findings  \\\n",
       "0  [{'explanation': 'Stubb, as the second mate on...   \n",
       "1  [{'explanation': 'Flask is a central figure in...   \n",
       "2  [{'explanation': 'Tashtego is depicted as a da...   \n",
       "3  [{'explanation': ''The Boat' is not only a phy...   \n",
       "4  [{'explanation': 'Brazil Banks is described as...   \n",
       "\n",
       "                                   full_content_json  \\\n",
       "0  {\\n    \"title\": \"Stubb and the Pequod's Mariti...   \n",
       "1  {\\n    \"title\": \"The Pequod's Whale Chase\",\\n ...   \n",
       "2  {\\n    \"title\": \"Tashtego and The Conflict Abo...   \n",
       "3  {\\n    \"title\": \"The Boat and the Whale Hunt\",...   \n",
       "4  {\\n    \"title\": \"Brazil Banks and Right Whales...   \n",
       "\n",
       "                                     id  \n",
       "0  991b0fc2-063c-43a1-965f-d1beacc3d969  \n",
       "1  dda93d78-a8c6-4147-8533-d25f2cbe13a5  \n",
       "2  ed60ddc1-b01d-47b8-8693-28dfbb21f091  \n",
       "3  67d866e8-5804-482f-a279-a5e1565e91ee  \n",
       "4  847adfb1-3f4a-4093-af5d-ea20c9039d8d  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "report_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")\n",
    "entity_embedding_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet\")\n",
    "\n",
    "reports = read_indexer_reports(report_df, entity_df, COMMUNITY_LEVEL)\n",
    "entities = read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)\n",
    "print(f\"Report records: {len(report_df)}\")\n",
    "report_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder = GlobalCommunityContext(\n",
    "    community_reports=reports,\n",
    "    entities=entities,  # default to None if you don't want to use community weights for ranking\n",
    "    token_encoder=token_encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "context_builder_params = {\n",
    "    \"use_community_summary\": False,  # False means using full community reports. True means using community short summaries.\n",
    "    \"shuffle_data\": True,\n",
    "    \"include_community_rank\": True,\n",
    "    \"min_community_rank\": 0,\n",
    "    \"community_rank_name\": \"rank\",\n",
    "    \"include_community_weight\": True,\n",
    "    \"community_weight_name\": \"occurrence weight\",\n",
    "    \"normalize_community_weight\": True,\n",
    "    \"max_tokens\": 12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "    \"context_name\": \"Reports\",\n",
    "}\n",
    "\n",
    "map_llm_params = {\n",
    "    \"max_tokens\": 1000,\n",
    "    \"temperature\": 0.0,\n",
    "    \"response_format\": {\"type\": \"json_object\"},\n",
    "}\n",
    "\n",
    "reduce_llm_params = {\n",
    "    \"max_tokens\": 2000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 1000-1500)\n",
    "    \"temperature\": 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine = GlobalSearch(\n",
    "    llm=llm,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    max_data_tokens=12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "    map_llm_params=map_llm_params,\n",
    "    reduce_llm_params=reduce_llm_params,\n",
    "    allow_general_knowledge=False,  # set this to True will add instruction to encourage the LLM to incorporate general knowledge in the response, which may increase hallucinations, but could be useful in some use cases.\n",
    "    json_mode=True,  # set this to False if your LLM model does not support JSON mode.\n",
    "    context_builder_params=context_builder_params,\n",
    "    concurrent_coroutines=32,\n",
    "    response_type=\"multiple paragraphs\",  # free form text describing the response type and format, can be anything, e.g. prioritized list, single paragraph, multiple paragraphs, multiple-page report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\graphrag\\query\\structured_search\\global_search\\search.py\", line 182, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 651, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 836, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 673, in _agenerate\n",
      "    payload = self._get_request_payload(messages, stop=stop, **kwargs)\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 557, in _get_request_payload\n",
      "    messages = self._convert_input(input_).to_messages()\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 232, in _convert_input\n",
      "    raise ValueError(\n",
      "ValueError: Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\graphrag\\query\\structured_search\\global_search\\search.py\", line 182, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 651, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 836, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 673, in _agenerate\n",
      "    payload = self._get_request_payload(messages, stop=stop, **kwargs)\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 557, in _get_request_payload\n",
      "    messages = self._convert_input(input_).to_messages()\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 232, in _convert_input\n",
      "    raise ValueError(\n",
      "ValueError: Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\graphrag\\query\\structured_search\\global_search\\search.py\", line 182, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 651, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 836, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 673, in _agenerate\n",
      "    payload = self._get_request_payload(messages, stop=stop, **kwargs)\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 557, in _get_request_payload\n",
      "    messages = self._convert_input(input_).to_messages()\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 232, in _convert_input\n",
      "    raise ValueError(\n",
      "ValueError: Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\graphrag\\query\\structured_search\\global_search\\search.py\", line 182, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 651, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 836, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 673, in _agenerate\n",
      "    payload = self._get_request_payload(messages, stop=stop, **kwargs)\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 557, in _get_request_payload\n",
      "    messages = self._convert_input(input_).to_messages()\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 232, in _convert_input\n",
      "    raise ValueError(\n",
      "ValueError: Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\graphrag\\query\\structured_search\\global_search\\search.py\", line 182, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 651, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 836, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 673, in _agenerate\n",
      "    payload = self._get_request_payload(messages, stop=stop, **kwargs)\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 557, in _get_request_payload\n",
      "    messages = self._convert_input(input_).to_messages()\n",
      "  File \"c:\\Users\\dschlesinger\\code\\ongoing\\azure-openai-code-samples\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 232, in _convert_input\n",
      "    raise ValueError(\n",
      "ValueError: Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sorry but I am unable to answer this question given the provided data.\n"
     ]
    }
   ],
   "source": [
    "result = await search_engine.asearch(\"How many people are mentioned in the book?\")\n",
    "\n",
    "print(result.response)\n",
    "# # inspect the data used to build the context for the LLM responses\n",
    "# result.context_data[\"reports\"]\n",
    "# # inspect number of LLM calls and tokens\n",
    "# print(f\"LLM calls: {result.llm_calls}. LLM tokens: {result.prompt_tokens}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
