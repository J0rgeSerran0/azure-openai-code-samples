{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid RAG with Azure Data Explorer  \n",
    "\n",
    "You can run this notebook after succesfully running these notebooks: \n",
    "- \"1- Create entities and embeddings\" \n",
    "- \"2- Save entities and embeddings into ADX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML, JSON, Markdown, Image\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "from azure.kusto.data import KustoClient, KustoConnectionStringBuilder\n",
    "from azure.kusto.data.exceptions import KustoServiceError\n",
    "from azure.kusto.data.helpers import dataframe_from_result_table\n",
    "\n",
    "\n",
    "# Configure environment variables\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_GPT4_32k_DEPLOYMENT_NAME = os.getenv(\"OPENAI_GPT4_32k_DEPLOYMENT_NAME\")\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "api_version = \"2024-02-01\"\n",
    "\n",
    "AAD_TENANT_ID = os.getenv(\"AAD_TENANT_ID\")\n",
    "KUSTO_CLUSTER = os.getenv(\"KUSTO_CLUSTER\")\n",
    "KUSTO_DATABASE = os.getenv(\"KUSTO_DATABASE\")\n",
    "KUSTO_TABLE = os.getenv(\"KUSTO_TABLE\")\n",
    "KUSTO_MANAGED_IDENTITY_APP_ID = os.getenv(\"KUSTO_MANAGED_IDENTITY_APP_ID\")\n",
    "KUSTO_MANAGED_IDENTITY_SECRET = os.getenv(\"KUSTO_MANAGED_IDENTITY_SECRET\")\n",
    "\n",
    "# define embeddings \n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,\n",
    "    azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "    openai_api_version=api_version,\n",
    "    chunk_size = 1\n",
    ")\n",
    "\n",
    "# call OpenAI to get the answer\n",
    "clientOpenAI = AzureOpenAI(\n",
    "  azure_endpoint = OPENAI_DEPLOYMENT_ENDPOINT, \n",
    "  api_key=OPENAI_API_KEY,  \n",
    "  api_version=\"2023-05-15\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use the tenacity library to create delays and retries when calling openAI embeddings to avoid hitting throttling limits\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def call_openAI(messages):\n",
    "    response = clientOpenAI.chat.completions.create(\n",
    "        model=OPENAI_GPT4_32k_DEPLOYMENT_NAME,\n",
    "        messages = messages,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "#we use the tenacity library to create delays and retries when calling openAI embeddings to avoid hitting throttling limits\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def calc_embeddings(text):\n",
    "    deployment = OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\n",
    "    # replace newlines, which can negatively affect performance.\n",
    "    txt = text.replace(\"\\n\", \" \")\n",
    "    return embeddings.embed_query(txt)\n",
    "\n",
    "\n",
    "\n",
    "def call_openAI_for_final_answer(question, answer):\n",
    "    prompt = 'Question: {}'.format(question) + '\\n' + 'Information: {}'.format(answer)\n",
    "    # prepare prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a HELPFUL assistant answering users questions. Answer the question using the provided information and do not add anything else.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}]\n",
    "    return call_openAI(messages)\n",
    "\n",
    "def prettyprint(text: str) -> str:\n",
    "    print(textwrap.fill(text, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to adx using AAD app registration\n",
    "cluster = KUSTO_CLUSTER\n",
    "kcsb = KustoConnectionStringBuilder.with_aad_application_key_authentication(cluster, KUSTO_MANAGED_IDENTITY_APP_ID, KUSTO_MANAGED_IDENTITY_SECRET,  AAD_TENANT_ID)\n",
    "client = KustoClient(kcsb)\n",
    "kusto_db = KUSTO_DATABASE\n",
    "embeddings_table = \"aviationIncidentsEmbeddings\"\n",
    "entities_table = \"aviationIncidentsEntities\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_from_adx(question, nr_of_answers=1):\n",
    "        searchedEmbedding = calc_embeddings(question)\n",
    "        kusto_query = embeddings_table + \" | extend similarity = series_cosine_similarity_fl(dynamic(\"+str(searchedEmbedding)+\"), embedding,1,1) | top \" + str(nr_of_answers) + \" by similarity desc \"\n",
    "        response = client.execute(kusto_db, kusto_query)\n",
    "\n",
    "        for row in response.primary_results[0]:\n",
    "                return row['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_in_NL_withOpenAI(question, nr_of_answers=2):\n",
    "    answer_from_ADX = get_embeddings_from_adx(question,nr_of_answers)\n",
    "    prompt = 'Question: {}'.format(question) + '\\n' + 'Information: {}'.format(answer_from_ADX)\n",
    "    # prepare prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": \"\"\"You are a HELPFUL assistant answering users questions. \n",
    "                Answer the question using the provided information only and do not add anything else.\n",
    "                \"\"\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    result = call_openAI(messages)\n",
    "    display(HTML(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The accident number for the aviation report occurred in the USA during the Phase of Operation: landing is SEA08CA052."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#asking Global questions using embeddings - we get only 2 answers - we cannot ask Global questions since we are limited\n",
    "# to 2 answers\n",
    "answer_in_NL_withOpenAI(\"List all the accident numbers for the aviation reports occurred in the USA during Phase of Operation: landing?\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's use GPT4 to translate the question to KQL\n",
    "def generate_KQL_query(question):\n",
    "    question_formatted = f\"\"\"You are a HELPFUL assistant translating Natural language to KQL queries. \n",
    "               \n",
    "                The Table in the database is called \"aviationIncidentsEntities\" and it has the following fields:\n",
    "                'document_id','document_name', 'entities'\n",
    "                The 'entities' field is a KQL dynamic field that contains the following properties:\n",
    "                aircraft_make:'',accident_number:'',aircraft_damage:'',city:'', state:'', country:'', phase_of_operation:'', pilot_flight_hours:'', engine_manufacturer:''\n",
    "                \n",
    "                Answer with the KQL query ONLY and do not add anything else.\n",
    "                \"\"\"\n",
    "    messages = [{\"role\": \"system\", \"content\": question_formatted},\n",
    "                {\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "    result = call_openAI(messages)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KQL query: aviationIncidentsEntities\n",
      "| where entities.country == \"USA\"\n",
      "| project entities.accident_number\n",
      "Number of results: 6\n",
      "List of accident numbers: NYC08CA055, SEA08CA049, SEA08CA052, NYC08CA040, NYC08CA073, NYC08CA068, \n"
     ]
    }
   ],
   "source": [
    "#Now let's combine ADX search and embeddings to answer the question\n",
    "query = generate_KQL_query(\"List all the accidents numbers occurred in the USA?\")\n",
    "print(\"KQL query: \" + query)\n",
    "\n",
    "#run the KQL query\n",
    "response = client.execute(kusto_db, query)\n",
    "nr_of_results = len(response.primary_results[0])\n",
    "print(\"Number of results: \" + str(nr_of_results))\n",
    "\n",
    "#extract the accident numbers\n",
    "list_of_accident_numbers = ''\n",
    "for row in response.primary_results[0]:\n",
    "    txt = (row[\"entities_accident_number\"])\n",
    "    list_of_accident_numbers += txt + ', '\n",
    "print(\"List of accident numbers: \" + list_of_accident_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The information provided does not include any accident numbers for aviation reports that occurred during the Phase of Operation: landing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_in_NL_withOpenAI(\"List all the accident numbers for the aviation reports occurred during Phase of Operation: landing from the following list: \" + list_of_accident_numbers, nr_of_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
